{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "BART-finetune",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shandarmodabbir/FineTuning-BART-for-text-summarization/blob/main/BART_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers peft datasets\n",
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:22:38.176961Z",
          "iopub.execute_input": "2025-01-05T02:22:38.177271Z",
          "iopub.status.idle": "2025-01-05T02:22:49.332139Z",
          "shell.execute_reply.started": "2025-01-05T02:22:38.177243Z",
          "shell.execute_reply": "2025-01-05T02:22:49.331008Z"
        },
        "id": "PoR5IvYbxPEL",
        "outputId": "3f18217d-0ed7-48d4-a778-be3d6d4bea8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nCollecting peft\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\nCollecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, peft\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\nSuccessfully installed huggingface-hub-0.27.0 peft-0.14.0\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.1+cu121)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "import logging\n"
      ],
      "metadata": {
        "id": "LLBn9hn6BifV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:22:49.333554Z",
          "iopub.execute_input": "2025-01-05T02:22:49.333879Z",
          "iopub.status.idle": "2025-01-05T02:23:02.422641Z",
          "shell.execute_reply.started": "2025-01-05T02:22:49.333857Z",
          "shell.execute_reply": "2025-01-05T02:23:02.421922Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "!jupyter nbextension install --py widgetsnbextension\n",
        "!pip install jupyterlab-widgets"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:23:27.190068Z",
          "iopub.execute_input": "2025-01-05T02:23:27.190383Z",
          "iopub.status.idle": "2025-01-05T02:23:34.275246Z",
          "shell.execute_reply.started": "2025-01-05T02:23:27.190356Z",
          "shell.execute_reply": "2025-01-05T02:23:34.274327Z"
        },
        "id": "0zj0P0MS1nNI",
        "outputId": "643cb892-5705-4917-861d-2adf59d0a659"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.5)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.13)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (71.0.4)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\nEnabling notebook extension jupyter-js-widgets/extension...\nPaths used for configuration of notebook: \n    \t/root/.jupyter/nbconfig/notebook.json\nPaths used for configuration of notebook: \n    \t\n      - Validating: \u001b[32mOK\u001b[0m\nPaths used for configuration of notebook: \n    \t/root/.jupyter/nbconfig/notebook.json\nInstalling /usr/local/lib/python3.10/dist-packages/widgetsnbextension/static -> jupyter-js-widgets\nUp to date: /usr/local/share/jupyter/nbextensions/jupyter-js-widgets/extension.js.LICENSE.txt\nUp to date: /usr/local/share/jupyter/nbextensions/jupyter-js-widgets/extension.js\nUp to date: /usr/local/share/jupyter/nbextensions/jupyter-js-widgets/extension.js.map\n- Validating: \u001b[32mOK\u001b[0m\n\n    To initialize this nbextension in the browser every time the notebook (or other app) loads:\n    \n          jupyter nbextension enable widgetsnbextension --py\n    \nRequirement already satisfied: jupyterlab-widgets in /usr/local/lib/python3.10/dist-packages (3.0.13)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Enable logging for progress tracking\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Load the dataset from Hugging Face Hub\n",
        "arxiv_dataset = load_dataset(\"ccdv/arxiv-summarization\")\n",
        "\n",
        "# Use only 10% of the dataset\n",
        "def sample_dataset(dataset, fraction=0.1):\n",
        "    return dataset.shuffle(seed=42).select(range(int(len(dataset) * fraction)))\n",
        "\n",
        "arxiv_dataset[\"train\"] = sample_dataset(arxiv_dataset[\"train\"], 0.1)\n",
        "arxiv_dataset[\"validation\"] = sample_dataset(arxiv_dataset[\"validation\"], 0.1)\n"
      ],
      "metadata": {
        "id": "UStU7Hx2mnxx",
        "outputId": "4d8870cd-9d40-4225-ddc4-c65feaf1507c",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:23:45.049305Z",
          "iopub.execute_input": "2025-01-05T02:23:45.049624Z",
          "iopub.status.idle": "2025-01-05T02:24:43.76234Z",
          "shell.execute_reply.started": "2025-01-05T02:23:45.049598Z",
          "shell.execute_reply": "2025-01-05T02:24:43.761311Z"
        },
        "colab": {
          "referenced_widgets": [
            "340f20b1134945b48671a5aa687090b0",
            "de47784814044edf982c3c468428260b",
            "7476985fb5744000b3d3b68c4a48bab3",
            "46b4474f032c4b1ba0c41218772086bb",
            "25dd4d25187846b8998941ba7a50391a",
            "dd619ca3d8e94434912999c4e41cfb60",
            "c43cd54dd73f4ea8a0b583e095a07253",
            "82f9b26e75c2413cbcd5f8e230cdcd96",
            "e7e57e4d85e94f15ba3d60aac3cd63f5",
            "bd4072d0a0fc4806ba73c639c0d0aab8",
            "51e437aa7b5d4bb2b45ca87d84f3eacd",
            "14c16738ae6a4ea088d3c8d827a082a6",
            "7228b9392bf54bf6bfd7175cc767ff13",
            "e40d08bbb3f14b6e91e15bf2b3395926",
            "4c0ff4eed672420192f50b4cdd08d71a",
            "45c533af66404c29a131770bbf170781",
            "0eaffe82cf754bbcb8b472efeef2d904",
            "46cadde4d8564ef2b530c5bf96c1de59",
            "23d00839b0d04750b6390a1abe941efc",
            "562476ab7bf44c6f84a151432d88e5a7",
            "ab2652b6e1654f90ad28ea6bdfd8c4cb"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/3.96k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "340f20b1134945b48671a5aa687090b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00000-of-00015.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de47784814044edf982c3c468428260b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00001-of-00015.parquet:   0%|          | 0.00/228M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7476985fb5744000b3d3b68c4a48bab3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00002-of-00015.parquet:   0%|          | 0.00/228M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46b4474f032c4b1ba0c41218772086bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00003-of-00015.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25dd4d25187846b8998941ba7a50391a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00004-of-00015.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd619ca3d8e94434912999c4e41cfb60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00005-of-00015.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c43cd54dd73f4ea8a0b583e095a07253"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00006-of-00015.parquet:   0%|          | 0.00/229M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82f9b26e75c2413cbcd5f8e230cdcd96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00007-of-00015.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7e57e4d85e94f15ba3d60aac3cd63f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00008-of-00015.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd4072d0a0fc4806ba73c639c0d0aab8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00009-of-00015.parquet:   0%|          | 0.00/228M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51e437aa7b5d4bb2b45ca87d84f3eacd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00010-of-00015.parquet:   0%|          | 0.00/229M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14c16738ae6a4ea088d3c8d827a082a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00011-of-00015.parquet:   0%|          | 0.00/231M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7228b9392bf54bf6bfd7175cc767ff13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00012-of-00015.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e40d08bbb3f14b6e91e15bf2b3395926"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00013-of-00015.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c0ff4eed672420192f50b4cdd08d71a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00014-of-00015.parquet:   0%|          | 0.00/235M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45c533af66404c29a131770bbf170781"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "validation-00000-of-00001.parquet:   0%|          | 0.00/105M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0eaffe82cf754bbcb8b472efeef2d904"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "test-00000-of-00001.parquet:   0%|          | 0.00/105M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46cadde4d8564ef2b530c5bf96c1de59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/203037 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23d00839b0d04750b6390a1abe941efc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/6436 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "562476ab7bf44c6f84a151432d88e5a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/6440 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab2652b6e1654f90ad28ea6bdfd8c4cb"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the BART model and tokenizer\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Apply LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    task_type=\"SEQ_2_SEQ_LM\",\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n"
      ],
      "metadata": {
        "id": "06B8SpTBm6iV",
        "outputId": "2add8c7e-40a6-4e30-f5f1-e8129c89e093",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:24:43.763531Z",
          "iopub.execute_input": "2025-01-05T02:24:43.763869Z",
          "iopub.status.idle": "2025-01-05T02:25:04.79493Z",
          "shell.execute_reply.started": "2025-01-05T02:24:43.763839Z",
          "shell.execute_reply": "2025-01-05T02:25:04.793977Z"
        },
        "colab": {
          "referenced_widgets": [
            "a1fde331313b4ffbbef31bd06ae63dce",
            "ecabcd966c1541ffbc35d08c0a27ff1f",
            "1f0b1de174554dd19ea2e8cff9dee42e",
            "4c7bb574449a43e29d78f85487212f61",
            "fe237b72f785414699ad5a0ad049f02f",
            "0a9eb1e451ef4d3eb4efe179b5024eb9"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1fde331313b4ffbbef31bd06ae63dce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecabcd966c1541ffbc35d08c0a27ff1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f0b1de174554dd19ea2e8cff9dee42e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c7bb574449a43e29d78f85487212f61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe237b72f785414699ad5a0ad049f02f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a9eb1e451ef4d3eb4efe179b5024eb9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize the dataset\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[\"article\"]\n",
        "    targets = examples[\"abstract\"]\n",
        "    model_inputs = tokenizer(inputs, max_length=1024, padding=\"max_length\", truncation=True)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=128, padding=\"max_length\", truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n"
      ],
      "metadata": {
        "id": "7_1odNsFm_a5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:25:04.796892Z",
          "iopub.execute_input": "2025-01-05T02:25:04.797126Z",
          "iopub.status.idle": "2025-01-05T02:25:04.801413Z",
          "shell.execute_reply.started": "2025-01-05T02:25:04.797107Z",
          "shell.execute_reply": "2025-01-05T02:25:04.800644Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply preprocessing with multiprocessing\n",
        "def tokenize_and_save(dataset, name):\n",
        "    tokenized_dataset = dataset.map(\n",
        "        preprocess_function,\n",
        "        batched=True,\n",
        "        remove_columns=dataset.column_names,\n",
        "        num_proc=4  # Adjust based on available CPU cores\n",
        "    )\n",
        "    tokenized_dataset.save_to_disk(f\"./tokenized_{name}_dataset\")\n",
        "    return tokenized_dataset\n"
      ],
      "metadata": {
        "id": "-gFepDw0nDLh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:25:04.802771Z",
          "iopub.execute_input": "2025-01-05T02:25:04.803022Z",
          "iopub.status.idle": "2025-01-05T02:25:04.824529Z",
          "shell.execute_reply.started": "2025-01-05T02:25:04.803003Z",
          "shell.execute_reply": "2025-01-05T02:25:04.823693Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = tokenize_and_save(arxiv_dataset[\"train\"], \"train\")\n",
        "val_dataset = tokenize_and_save(arxiv_dataset[\"validation\"], \"val\")\n"
      ],
      "metadata": {
        "id": "iB2j-mF0nI4i",
        "outputId": "84d4cba2-f59c-45d6-b2af-aa85b86b3ea8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:25:04.825362Z",
          "iopub.execute_input": "2025-01-05T02:25:04.825655Z",
          "iopub.status.idle": "2025-01-05T02:31:36.511027Z",
          "shell.execute_reply.started": "2025-01-05T02:25:04.825627Z",
          "shell.execute_reply": "2025-01-05T02:31:36.510093Z"
        },
        "colab": {
          "referenced_widgets": [
            "811fe3cebd5e4ffd9fe66d14e6cd5e2b",
            "d1138a5b782741598435942373f08c8e",
            "aff629e8fba246238a356c51e7dfa6a2",
            "5d96f9c76aaf4d1bb80a5004077ddbcf"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=4):   0%|          | 0/20303 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "811fe3cebd5e4ffd9fe66d14e6cd5e2b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/20303 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1138a5b782741598435942373f08c8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=4):   0%|          | 0/643 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aff629e8fba246238a356c51e7dfa6a2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/643 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d96f9c76aaf4d1bb80a5004077ddbcf"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define data collator for padding during batching\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
      ],
      "metadata": {
        "id": "pWwO9d3znMqQ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:31:36.512051Z",
          "iopub.execute_input": "2025-01-05T02:31:36.51235Z",
          "iopub.status.idle": "2025-01-05T02:31:36.515915Z",
          "shell.execute_reply.started": "2025-01-05T02:31:36.512321Z",
          "shell.execute_reply": "2025-01-05T02:31:36.515167Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:31:36.516605Z",
          "iopub.execute_input": "2025-01-05T02:31:36.516876Z",
          "iopub.status.idle": "2025-01-05T02:31:45.216635Z",
          "shell.execute_reply.started": "2025-01-05T02:31:36.516855Z",
          "shell.execute_reply": "2025-01-05T02:31:45.215772Z"
        },
        "id": "piNPEmpp1nNO",
        "outputId": "b5a5d4fc-b7af-4fd6-cfda-67540c47d8ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=dacea472065ef26ad52a56c5daa369d0653e7cf9b035fc951b1c30f8e3168381\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "# Load the ROUGE metric using the evaluate library\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "# Function to compute metrics\n",
        "def compute_metrics(pred):\n",
        "    # Decode predictions and references\n",
        "    decoded_preds = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    # Extract the desired scores (e.g., ROUGE-2 F1 score)\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    return result\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:31:45.21886Z",
          "iopub.execute_input": "2025-01-05T02:31:45.219075Z",
          "iopub.status.idle": "2025-01-05T02:31:47.463686Z",
          "shell.execute_reply.started": "2025-01-05T02:31:45.219057Z",
          "shell.execute_reply": "2025-01-05T02:31:47.462761Z"
        },
        "id": "S-YX_DQm1nNP",
        "outputId": "f28a124e-dc7b-4e6d-874f-da7926347fd1",
        "colab": {
          "referenced_widgets": [
            "2b1b765a227846ffbc7e787ce623485f"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b1b765a227846ffbc7e787ce623485f"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define training arguments\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./bart-arxiv-summarization\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    gradient_accumulation_steps=4,\n",
        "    dataloader_num_workers=4,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=[\"tensorboard\"]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "sQKaMW9DnPuu",
        "outputId": "af1bfbf6-f9e4-448d-c651-121629a63432",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:31:47.464918Z",
          "iopub.execute_input": "2025-01-05T02:31:47.465263Z",
          "iopub.status.idle": "2025-01-05T02:31:48.021055Z",
          "shell.execute_reply.started": "2025-01-05T02:31:47.465229Z",
          "shell.execute_reply": "2025-01-05T02:31:48.020128Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n"
      ],
      "metadata": {
        "id": "W09f6Q6AnTE_",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:31:48.022015Z",
          "iopub.execute_input": "2025-01-05T02:31:48.022341Z",
          "iopub.status.idle": "2025-01-05T02:31:48.669419Z",
          "shell.execute_reply.started": "2025-01-05T02:31:48.022306Z",
          "shell.execute_reply": "2025-01-05T02:31:48.668733Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "VgkijkTWnU4e",
        "outputId": "1825ade9-5fa3-4ae3-e37c-f927dc19f265",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:31:48.670151Z",
          "iopub.execute_input": "2025-01-05T02:31:48.670379Z",
          "iopub.status.idle": "2025-01-05T02:31:48.810946Z",
          "shell.execute_reply.started": "2025-01-05T02:31:48.670358Z",
          "shell.execute_reply": "2025-01-05T02:31:48.810043Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainerCallback\n",
        "\n",
        "class ProgressCallback(TrainerCallback):\n",
        "    def on_train_begin(self, args, state, control, **kwargs):\n",
        "        # Called at the start of training.\n",
        "        print(\"Training has started.\")\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        # Logs training progress during the training process.\n",
        "        if logs is not None:\n",
        "            print(f\"Step {state.global_step}: {logs}\")\n",
        "\n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        # Called at the end of training.\n",
        "        print(\"Training has ended.\")\n",
        "\n",
        "\n",
        "# Add the custom callback\n",
        "trainer.add_callback(ProgressCallback())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:31:48.811778Z",
          "iopub.execute_input": "2025-01-05T02:31:48.812058Z",
          "iopub.status.idle": "2025-01-05T02:31:48.818286Z",
          "shell.execute_reply.started": "2025-01-05T02:31:48.812033Z",
          "shell.execute_reply": "2025-01-05T02:31:48.817453Z"
        },
        "id": "_ULePwfS1nNR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "print(\"Training...\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "ua0mXjs4nW6w",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T02:31:59.819761Z",
          "iopub.execute_input": "2025-01-05T02:31:59.820095Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "trainer.save_model(\"./fine_tuned_bart\")\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(\"./fine_tuned_bart\")"
      ],
      "metadata": {
        "outputId": "f04e0a02-99a3-4c69-f796-b7e9effb753d",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T04:07:00.038863Z",
          "iopub.execute_input": "2025-01-05T04:07:00.03917Z",
          "iopub.status.idle": "2025-01-05T04:07:00.585178Z",
          "shell.execute_reply.started": "2025-01-05T04:07:00.039148Z",
          "shell.execute_reply": "2025-01-05T04:07:00.584275Z"
        },
        "_kg_hide-output": true,
        "id": "lnLn00Zo1nNS"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "('./fine_tuned_bart/tokenizer_config.json',\n './fine_tuned_bart/special_tokens_map.json',\n './fine_tuned_bart/vocab.json',\n './fine_tuned_bart/merges.txt',\n './fine_tuned_bart/added_tokens.json')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "fine_tuned_model_path = \"./fine_tuned_bart\"\n",
        "model = BartForConditionalGeneration.from_pretrained(fine_tuned_model_path)\n",
        "tokenizer = BartTokenizer.from_pretrained(fine_tuned_model_path)\n",
        "\n",
        "# Function to summarize a paragraph\n",
        "def summarize_text(paragraph):\n",
        "    inputs = tokenizer(paragraph, max_length=10240, return_tensors=\"pt\", truncation=True)\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {key: value.cuda() for key, value in inputs.items()}\n",
        "        model.cuda()\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=1280, min_length=30, length_penalty=2.0, num_beams=4)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Example usage\n",
        "paragraph = \"\"\"Application of machine learning has become prominent in many fields and has captured\n",
        "the imaginations of various industries. The development of data driven algorithms and the\n",
        "ongoing digitization of subsurface geological measurements provide a world of\n",
        "opportunities to maximize the exploration and production of resources such as oil, gas,\n",
        "coal and geothermal energy. The current proliferation of data, democratization of state-of-\n",
        "the-art processing technology and computation power provide an avenue for both large\n",
        "and small industry players to maximize the use of their data to run more economic and\n",
        "efficient operations. The aim of this thesis is to discuss the development of robust data-\n",
        "driven methods and their effectiveness in providing insightful information about\n",
        "subsurface properties. The study opens with a brief overview of the current literature\n",
        "regarding application of data driven methods in the oil and gas industry.\n",
        "Outlier detection can be a strenuous task when data preprocessing for purposes of\n",
        "data- driven modeling. The thesis presents the efficacy of unsupervised outlier detection\n",
        "algorithms for various practical cases by comparing the performance of four outlier\n",
        "detection algorithms using appropriate metrics. Three case were created simulating: noisy\n",
        "measurements, measurements from washout formation and measurements from\n",
        "formations with several thin shale layers. It was observed that the Isolation Forest based\n",
        "model is efficient in detecting a wide range of outlier types with a balanced accuracy score\n",
        "of 0.88, 0.93 and 0.96 for the respective cases, while the DBSCAN based model was\n",
        "effective at detecting outliers due to noisy measurement with balanced accuracy score of NMR measurements provide a wealth of geological information for petrophysical analysis\n",
        "and can be key in accurately characterizing a reservoir, however they are expensive and\n",
        "technically challenging to deploy, it has been shown in research that machine learning\n",
        "models can be effective in synthesizing some log data. However, predicting an NMR\n",
        "distribution where each depth is represented by several bins poses a different challenge.\n",
        "In this study, a Random Forest model was used for predicting the NMR T1 distribution in\n",
        "a well using relatively inexpensive and readily available well logs with an r2 score and\n",
        "corrected Mean absolute percentage error of 0.14 and 0.84. The predictions fall within the\n",
        "margin of error and an index was proposed to evaluate the reliability of each prediction\n",
        "based on a quantile regression forest to provide the user more information on the accuracy\n",
        "of the prediction when no data is available to test the model as will be the case in real\n",
        "world application. Using this method engineers and geologist can obtain NMR derived\n",
        "information from a well when no NMR tool has been run with a measure of reliability for\n",
        "each predicted sample/depth.\"\"\"\n",
        "\n",
        "summary = summarize_text(paragraph)\n",
        "print(\"Original Paragraph:\")\n",
        "print(paragraph)\n",
        "print(\"\\nGenerated Summary:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T04:11:18.301475Z",
          "iopub.execute_input": "2025-01-05T04:11:18.301813Z",
          "iopub.status.idle": "2025-01-05T04:11:19.987254Z",
          "shell.execute_reply.started": "2025-01-05T04:11:18.301785Z",
          "shell.execute_reply": "2025-01-05T04:11:19.986511Z"
        },
        "id": "7y0hmSLR1nNS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "rO6NqQWb1nNT"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}